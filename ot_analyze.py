import json
import os
import subprocess
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List

from write_failed_analysis import write_failed_analysis


def generate_analysis_path(protocol_file: Path) -> Path:
    """
    Takes a Path to a protocol file and returns a Path to the analysis file that
    should be generated by the analyze command.

    :param protocol_file: A Path to a protocol file.
    :return: A Path to the analysis file that should be generated by the analyze command.
    """
    return Path(protocol_file.parent, f"{protocol_file.stem}_analysis.json")


def analyze(protocol_file: Path):
    start_time = time.time()  # Start timing
    analysis_file = generate_analysis_path(protocol_file)
    custom_labware_directory = Path(protocol_file.parent, "custom_labware")

    custom_labware = []
    # PD protocols contain their own custom labware
    if custom_labware_directory.is_dir() and protocol_file.suffix == ".py":
        custom_labware = [
            os.path.join(custom_labware_directory, file) for file in os.listdir(custom_labware_directory) if file.endswith(".json")
        ]

    command = [
        "python",
        "-I",
        "-m",
        "opentrons.cli",
        "analyze",
        "--json-output",
        analysis_file,
        protocol_file,
    ] + custom_labware
    try:
        subprocess.run(command, capture_output=True, text=True, check=True)
    except Exception as e:
        print(f"Error in analysis of {protocol_file}")
        write_failed_analysis(analysis_file, e)
        end_time = time.time()
        return end_time - start_time
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Successful analysis of {protocol_file} completed in {elapsed_time:.2f} seconds")
    return elapsed_time


def run_analyze_in_parallel(protocol_files: List[Path]):
    start_time = time.time()
    with ThreadPoolExecutor() as executor:
        futures = [executor.submit(analyze, file) for file in protocol_files]
        accumulated_time = 0
        for future in as_completed(futures):
            try:
                accumulated_time += future.result()  # This blocks until the future is done
            except Exception as e:
                print(f"An error occurred: {e}")
        end_time = time.time()
        clock_time = end_time - start_time
        print(
            f"""{len(protocol_files)} protocols with total analysis time of {accumulated_time:.2f}seconds.
Analyzed in {clock_time:2f} seconds thanks to parallelization.
"""
        )


def find_python_protocols(directory: Path) -> List[Path]:
    # Check if the provided path is a valid directory

    if not directory.is_dir():
        raise NotADirectoryError(f"The path {directory} is not a valid directory.")

    # Recursively find all .py files
    python_files = list(directory.rglob("*.py"))
    # TODO: shallow test that they are valid protocol files
    return python_files


def has_designer_application(json_file_path):
    try:
        with open(json_file_path, "r", encoding="utf-8") as file:
            data = json.load(file)
            return "designerApplication" in data
    except json.JSONDecodeError:
        # Handle the exception if the file is not a valid JSON
        print(f"Invalid JSON file: {json_file_path}")
        return False


def find_pd_protocols(directory: Path) -> List[Path]:
    # Check if the provided path is a valid directory
    if not directory.is_dir():
        raise NotADirectoryError(f"The path {directory} is not a valid directory.")

    # Recursively find all .json files
    json_files = list(directory.rglob("*.json"))
    filtered_json_files = [file for file in json_files if has_designer_application(file)]
    return filtered_json_files


def main():
    repo_relative_path = Path(os.getenv("GITHUB_WORKSPACE"), os.getenv("INPUT_BASE_DIRECTORY"))
    print("Hello World")
    print(f"Analyzing all protocol files in {repo_relative_path}")
    python_files = find_python_protocols(repo_relative_path)
    pd_files = find_pd_protocols(repo_relative_path)
    all_protocol_files = python_files + pd_files
    run_analyze_in_parallel(all_protocol_files)


if __name__ == "__main__":
    main()
